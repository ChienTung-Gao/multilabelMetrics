{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an example for the use of the library with a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firs we will load the functions of the library\n",
    "from multilabelMetrics.exampleBasedClassification import eb_accuracy, eb_fbeta, eb_precision, eb_recall, subsetAccuracy, hammingLoss\n",
    "from multilabelMetrics.labelBasedRanking import aucMicro, aucMacro, aucInstance\n",
    "from multilabelMetrics.exampleBasedRanking import oneError, coverage, rankingLoss, averagePrecision\n",
    "from multilabelMetrics.labelBasedClassification import accuracyMicro, accuracyMacro, precisionMicro, precisionMacro, recallMacro, recallMicro, fbetaMicro, fbetaMacro\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from auxiliaryFunctions import readParams, readDataFromFile\n",
    "#And some libraries to test our code using the MLkNN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will load the data and train the model, later on we will show all the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain = readDataFromFile('emotions0.train')\n",
    "Xtest, ytest = readDataFromFile('emotions0.gen')\n",
    "classifier = MLkNN(k=10)\n",
    "classifier.fit(Xtrain, ytrain)\n",
    "y_pred = classifier.predict(Xtest)\n",
    "y_pred = y_pred.todense()\n",
    "probabilities = classifier.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing all the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example based Accuracy: 0.3763888888888889283634853200\n",
      "Example based Precision: 0.5111111111111111308484093267\n",
      "Example based FBeta: 0.4690196078431373129408862377\n",
      "Example based Recall: 0.4333333333333333925452279800\n",
      "Subset Accuracy: 0.1833333333333333333333333333\n",
      "Hamming Loss: 0.2138888888888888888888888888\n",
      "Accuracy Micro: 0.7305555555555555555555555557\n",
      "Accuracy Macro: 0.7305555555555555555555555557\n",
      "Precision Micro: 0.4454545454545454545454545453\n",
      "Precision Macro: 0.4241165592042785025241165593\n",
      "Recall Micro: 0.5764705882352941176470588234\n",
      "Recall Macro: 0.5259920634920635\n",
      "FBeta Micro: 0.5025641025641025276644750892\n",
      "FBeta Macro: 0.4632047473223943812179106295\n",
      "OneError: 0.7333333333333333333333333333\n",
      "Coverage: 2.733333333333333333333333333\n",
      "Ranking Loss: 0.4791666666666666666666666667\n",
      "Average Precision: 0.5337962962962965463020736934\n",
      "AUCMicro: 0.8513818181818181818181818182\n",
      "AUCMacro: 0.9180244267388784074057639373\n",
      "AUCInstance: 0.4059413580246912900406641711\n"
     ]
    }
   ],
   "source": [
    "print(\"Example based Accuracy: \" + str(eb_accuracy(ytest, y_pred)))\n",
    "print(\"Example based Precision: \"+ str(eb_precision(ytest, y_pred)))\n",
    "print(\"Example based FBeta: \" + str(eb_fbeta(ytest, y_pred)))\n",
    "print(\"Example based Recall: \" + str(eb_recall(ytest, y_pred)))\n",
    "print(\"Subset Accuracy: \" + str(subsetAccuracy(ytest, y_pred)))\n",
    "print(\"Hamming Loss: \" + str(hammingLoss(ytest, y_pred)))\n",
    "print(\"Accuracy Micro: \" + str(accuracyMicro(ytest, y_pred)))\n",
    "print(\"Accuracy Macro: \" + str(accuracyMacro(ytest, y_pred)))\n",
    "print(\"Precision Micro: \" + str(precisionMicro(ytest, y_pred)))\n",
    "print(\"Precision Macro: \" + str(precisionMacro(ytest, y_pred)))\n",
    "print(\"Recall Micro: \" + str(recallMicro(ytest, y_pred)))\n",
    "print(\"Recall Macro: \" + str(recallMacro(ytest, y_pred)))\n",
    "print(\"FBeta Micro: \" + str(fbetaMicro(ytest, y_pred)))\n",
    "print(\"FBeta Macro: \" + str(fbetaMacro(ytest, y_pred)))\n",
    "print(\"OneError: \" + str(oneError(ytest, y_pred)))\n",
    "print(\"Coverage: \" + str(coverage(ytest, y_pred)))\n",
    "print(\"Ranking Loss: \" + str(rankingLoss(ytest, y_pred)))\n",
    "print(\"Average Precision: \" + str(averagePrecision(ytest, y_pred)))\n",
    "print(\"AUCMicro: \" + str(aucMicro(ytest, y_pred)))\n",
    "print(\"AUCMacro: \" + str(aucMacro(ytest, y_pred)))\n",
    "print(\"AUCInstance: \" + str(aucInstance(ytest, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
